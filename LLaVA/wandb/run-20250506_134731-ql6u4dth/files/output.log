  0%|                                                                 | 0/12500 [00:00<?, ?it/s]/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(137)forward()
-> preds = self.new_head(hidden_states[:, :-1, :])
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(138)forward()
-> target = torch.ones(100).to(preds.device)
<class 'torch.Tensor'>
tensor([[[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 1.1406,  2.2031, -1.2344,  ..., -0.6445,  3.6406, -0.1416],
         [ 1.3203,  2.8281, -1.9766,  ..., -0.9883,  1.8672, -0.0469],
         [ 1.7656,  1.8828, -1.4141,  ..., -0.3672,  3.4688, -0.7148]],

        [[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        ...,

        [[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 2.8281,  0.8125, -0.5859,  ..., -0.5391,  4.6875, -0.9141],
         [ 2.1094,  2.1094, -0.1641,  ...,  0.2598,  4.4375, -0.4199],
         [ 1.6406,  2.2656,  0.5156,  ..., -0.3164,  4.1875, -0.5742]],

        [[ 0.7266, -1.0703,  0.3672,  ...,  1.9062,  1.1328,  4.0938],
         [-2.1562, -2.0000, -0.5273,  ..., -1.4297, -0.7695, -2.2656],
         [-0.3555,  3.0156, -0.5391,  ...,  0.5469,  1.6094, -1.2578],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<PreBackwardFunctionBackward>)
torch.bfloat16
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 138, in forward
    target = torch.ones(100, dtype=  preds.dtype ).to(preds.device)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 138, in forward
    target = torch.ones(100, dtype=  preds.dtype ).to(preds.device)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 138, in forward
    target = torch.ones(100, dtype=  preds.dtype ).to(preds.device)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 138, in forward
    target = torch.ones(100, dtype=  preds.dtype ).to(preds.device)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
