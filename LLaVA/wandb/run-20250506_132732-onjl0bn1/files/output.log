  0%|                                                                 | 0/12500 [00:00<?, ?it/s]/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(137)forward()
-> preds = self.new_head(hidden_states[:, :-1, :])
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(138)forward()
-> target = torch.ones(100).to(preds.device)
torch.Size([16, 739, 100])
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(139)forward()
-> target = target.detach()  # Just to be explicit, even if requires_grad=False by default
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(142)forward()
-> target_expanded = target.view(1, 1, 100)  # shape (1, 1, 100)
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(143)forward()
-> target_expanded = target_expanded.expand_as(preds)  # shape (16, 740, 100)
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(146)forward()
-> mse_loss = F.mse_loss(preds, target_expanded)
torch.Size([16, 739, 100])
*** NameError: name 'targets' is not defined
tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0')
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(147)forward()
-> loss += 10 * mse_loss
tensor(4.8858, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(11.4977, device='cuda:0', grad_fn=<NllLossBackward0>)
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(148)forward()
-> if not return_dict:
tensor(60.3558, device='cuda:0', grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 148, in forward
    if not return_dict:
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 148, in forward
    if not return_dict:
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 148, in forward
    if not return_dict:
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 148, in forward
    if not return_dict:
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
