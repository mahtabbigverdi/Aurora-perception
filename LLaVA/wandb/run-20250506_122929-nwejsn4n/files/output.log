  0%|                                                                 | 0/12500 [00:00<?, ?it/s]/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(100)forward()
-> outputs = self.model(
True
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(101)forward()
-> input_ids=input_ids,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(102)forward()
-> attention_mask=attention_mask,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(103)forward()
-> position_ids=position_ids,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(104)forward()
-> past_key_values=past_key_values,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(105)forward()
-> inputs_embeds=inputs_embeds,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(106)forward()
-> use_cache=use_cache,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(107)forward()
-> output_attentions=output_attentions,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(108)forward()
-> output_hidden_states=output_hidden_states,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(109)forward()
-> return_dict=return_dict,
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(100)forward()
-> outputs = self.model(
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(112)forward()
-> hidden_states = outputs[0]
*** AttributeError: 'BaseModelOutputWithPast' object has no attribute 'shape'
*** NameError: name 'hidden_states' is not defined
> /mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py(113)forward()
-> if self.config.pretraining_tp > 1:
BaseModelOutputWithPast(last_hidden_state=tensor([[[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [-1.0625,  0.7930, -0.1475,  ..., -0.7500, -0.8633, -0.5586],
         [-1.0547,  1.6406,  0.5078,  ..., -1.1172, -0.6602, -0.5234],
         [ 0.9922,  0.3848,  1.6875,  ..., -0.9727,  0.0259, -1.5938]],

        [[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        ...,

        [[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [-1.3125,  1.4922,  0.4688,  ..., -2.2969,  0.0393, -0.6055],
         [-1.0547,  2.1875,  0.7930,  ..., -1.6953, -0.4238, -0.7539],
         [ 1.1406, -0.0209,  1.8359,  ..., -1.4766,  0.1021, -2.1406]],

        [[ 0.2422, -0.1279,  0.1138,  ...,  0.0771, -0.1187,  0.1445],
         [ 0.4336, -0.7852, -2.2969,  ...,  1.0547,  1.6719,  0.4629],
         [ 1.0469,  0.9688,  1.3516,  ..., -1.0625, -0.7461,  0.1523],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<PreBackwardFunctionBackward>), past_key_values=None, hidden_states=None, attentions=None)
torch.Size([16, 740, 4096])
torch.Size([16, 4096])
*** NameError: name 'inputs' is not defined
*** AttributeError: 'NoneType' object has no attribute 'shape'
torch.Size([16, 740, 4096])
torch.Size([16, 739, 4096])
torch.Size([16, 739, 100])
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 113, in forward
    if self.config.pretraining_tp > 1:
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 113, in forward
    if self.config.pretraining_tp > 1:
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Traceback (most recent call last):
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train.py", line 1016, in train
    trainer.train()
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 113, in forward
    if self.config.pretraining_tp > 1:
  File "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/model/language_model/llava_llama.py", line 113, in forward
    if self.config.pretraining_tp > 1:
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gscratch/krishna/mahtab/miniconda3/envs/newllava/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
