{
  "os": "Linux-4.18.0-513.18.1.el8_9.x86_64-x86_64-with-glibc2.28",
  "python": "CPython 3.10.16",
  "startedAt": "2025-03-27T03:26:09.853481Z",
  "args": [
    "--local_rank=0",
    "--lora_enable",
    "True",
    "--lora_r",
    "128",
    "--lora_alpha",
    "256",
    "--mm_projector_lr",
    "2e-5",
    "--deepspeed",
    "./scripts/zero3.json",
    "--depth_data",
    "True",
    "--annealing_data",
    "True",
    "--custom_image_size",
    "336",
    "--model_name_or_path",
    "liuhaotian/llava-v1.5-13b",
    "--version",
    "v1",
    "--data_path",
    "/gscratch/krishna/mahtab/LLaVA/train_annealing_data.json",
    "--image_folder",
    "/",
    "--vision_tower",
    "openai/clip-vit-large-patch14-336",
    "--mm_projector_type",
    "mlp2x_gelu",
    "--mm_vision_select_layer",
    "-2",
    "--mm_use_im_start_end",
    "False",
    "--mm_use_im_patch_token",
    "False",
    "--image_aspect_ratio",
    "pad",
    "--group_by_modality_length",
    "False",
    "--bf16",
    "True",
    "--output_dir",
    "./checkpoints/train_depth_annealing-llava-v1.5-13b-task-lora-test",
    "--num_train_epochs",
    "1",
    "--per_device_train_batch_size",
    "16",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "1",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "20",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-4",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "True",
    "--model_max_length",
    "2048",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--lazy_preprocess",
    "True",
    "--report_to",
    "wandb"
  ],
  "program": "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA/llava/train/train_mem.py",
  "codePath": "LLaVA/llava/train/train_mem.py",
  "git": {
    "remote": "https://github.com/mahtabbigverdi/Aurora-perception.git",
    "commit": "e30ef4a11a8a9383314e1f7e170214b3f8f1ddba"
  },
  "email": "mahtab@cs.washington.edu",
  "root": "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/LLaVA",
  "host": "g3122",
  "executable": "/gscratch/krishna/mahtab/miniconda3/envs/newllava/bin/python",
  "codePathLocal": "llava/train/train_mem.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA L40S",
  "gpu_count": 8,
  "disk": {
    "/": {
      "total": "811496742912",
      "used": "7786024960"
    }
  },
  "memory": {
    "total": "1622993489920"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    },
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada"
    }
  ],
  "slurm": {
    "cluster_name": "klone",
    "conf": "/var/spool/slurmd/conf-cache/slurm.conf",
    "cpus_on_node": "20",
    "cpus_per_task": "20",
    "gpus_on_node": "8",
    "gtids": "0",
    "job_account": "krishna",
    "job_cpus_per_node": "20",
    "job_end_time": "1743269540",
    "job_gid": "226269",
    "job_gpus": "0,1,2,3,4,5,6,7",
    "job_id": "25047153",
    "job_name": "interactive",
    "job_nodelist": "g3122",
    "job_num_nodes": "1",
    "job_partition": "gpu-l40s",
    "job_qos": "krishna-gpu-l40s",
    "job_start_time": "1743022940",
    "job_uid": "1251047",
    "job_user": "mahtab",
    "jobid": "25047153",
    "launch_node_ipaddr": "10.64.64.100",
    "localid": "0",
    "mem_per_node": "204800",
    "mpi_type": "none",
    "nnodes": "1",
    "nodeid": "0",
    "nodelist": "g3122",
    "oom_kill_step": "0",
    "prio_process": "0",
    "procid": "0",
    "pty_port": "36391",
    "pty_win_col": "84",
    "pty_win_row": "18",
    "script_context": "prolog_task",
    "srun_comm_host": "10.64.64.100",
    "srun_comm_port": "43479",
    "step_id": "4294967290",
    "step_launcher_port": "43479",
    "step_nodelist": "g3122",
    "step_num_nodes": "1",
    "step_num_tasks": "1",
    "step_tasks_per_node": "1",
    "stepid": "4294967290",
    "submit_dir": "/mmfs1/gscratch/krishna/mahtab/Aurora-perception/AiT",
    "submit_host": "klone-login03",
    "task_pid": "37526",
    "tasks_per_node": "1",
    "topology_addr": "klone-ib-core.klone-ib-leaf-6j16-1.g3122",
    "topology_addr_pattern": "switch.switch.node",
    "tres_per_task": "cpu=20"
  },
  "cudaVersion": "12.7"
}